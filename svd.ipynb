{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Modinat-A/SVD/blob/main/svd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRUrAHlZKdWd"
      },
      "source": [
        "# C4AI Scholars Program Takehome Challenge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4wvFv6lTbY"
      },
      "source": [
        "### Background\n",
        "\n",
        "Welcome to the C4AI Scholars Program Take-Home Challenge! This exercise is designed to allow you to showcase your engineering and problem solving skills. The Challenge consists of three parts:\n",
        "\n",
        "* Part One of the challenge requires identifying bugs, and getting the code working. This is designed to test your ability to grapple with real world engineering challenges.\n",
        "* Part Two of the challenge tests your ability to generate code for a specified problem.\n",
        "* Part Three of the challenge is an opportunity for you to attempt an optional challenge question that extends the original problem set.\n",
        "\n",
        "\n",
        "These tasks were chosen as a setting to see how you think about problems, even if they are not in your own research field of interest. The tasks and dataset are not meant to be indicative of the research goals of the Scholar Program. We purposefully have selected a simple toy problem so the focus is on how you think, and does not require significant machine learning resources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmbPmOHhLx4U"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc-enDOhazoe"
      },
      "source": [
        "## Overview of Singular Value Decomposition\n",
        "\n",
        "In this takehome, you will be working on a problem involving singular value decomposition. Singular Value Decomposition (SVD) exists for every rectangular matrix. The nice thing about SVD is that the original matrix can be expressed as the sum of outer products of left and singular vectors scaled by the corresponding singular values. Formally:\n",
        "\n",
        "> Let 𝛢 be a rectangular matrix of dimensions 𝑚𝘹𝑛, then the SVD of the matrix A is given by $ A = U𝛴V^T$ where $U$ is an orthogonal matrix of shape mxm containing the left singular vectors, $V$ is an orthogonal matrix of shape nxn containing the right singular vectors and $𝛴$ is a diagonal matrix containing the singular values of $A$. This formulation of SVD can be re-expressed as \\begin{align} A = \\sum_{i=1}^{r} s_i. u_i v_i^T \\end{align} where $r = \\text{min}(m,n)$ represents the rank of the matrix, $s_i$ is the $i$th singular value and $u_i v_i^T$ is the outer product of the $i$th left and right singular vectors.\n",
        "\n",
        "<!-- \\begin{align}\n",
        "A = \\sum_{i=1}^{\\text{min}(m,n)} s_i. u_i v_i^T\n",
        "\\end{align}\n",
        "\\begin{align} -->\n",
        "\n",
        "> The singular values $𝛴$ are decreasing in order. So, each outer product is scaled by a smaller value as we compute each term in the sum above. This gives us an opportunity to approximate $A$ using only the sum of the first $k$ outer products where $k < \\text{min}(m,n)$ $-$ this effectively means that we are zero-ing out some of the singular values by assuming that the contribution to the sum is negligible. This is called low-rank approximation.\n",
        "\n",
        "If you aren't familiar with singular value decomposition, or the above feels rusty, don't worry. Take a moment to brush up your knowledge using any of the following resources:\n",
        "* [stanford lecture notes on low rank approximations](https://web.stanford.edu/class/cs168/l/l9.pdf)\n",
        "* [youtube series of short and beginner friendly lectures](https://www.youtube.com/watch?v=gXbThCXjZFM&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcL7u9wJjPF3"
      },
      "source": [
        "## Check for understanding (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v-iHTH3nasL"
      },
      "source": [
        "#### Q1: What are some real world applications of low rank approximations?\n",
        "\n",
        "\n",
        "#### Answer:\n",
        "\n",
        "\n",
        "1.   Facial recognition on google photos to distguish faces\n",
        "2.   Page ranking algorithm on google to present websites according to importance\n",
        "3.   Recommender systems in Netflix\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHGqpn3tkFRL"
      },
      "source": [
        "#### Q2: What are the benefits of compressing a deep neural network? How would you measure the benefits of compression?\n",
        "\n",
        "\n",
        "#### Answer:\n",
        "\n",
        "1.   It reduces latency by reducing the amount of time the model is able to make a prediction\n",
        "2.   It reduces the memory consumed by the model which can be mesured by the memory consumed in bytes\n",
        "4.   Faster processsing , If the models can be compressed to stay on mobile devices then the model doesnt have to be stored externally and retraining and predictions can be done on the device\n",
        "5 Compression does not affect model prediction accuracy\n",
        "Reduces redundancy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9r4v5vng9ma"
      },
      "source": [
        "#### Q3: In this takehome, we will consider how singular value decomposition can be used to compress a deep neural network. Compared to other compression methods used for deep neural networks such as pruning, quantization, or efficient architectures, what are the relative merits/demerits of low rank approximations? Choose one or two alternative compression methods and compare with singular value decomposition.\n",
        "\n",
        "#### Answer:\n",
        "Merits of low rank approximations\n",
        "\n",
        "\n",
        "1.   They are better at preserving prediction accuracy capabilities of the nueral network compared to prunning and quatization. In prunning the accuracy can be affected when it tries to remove repetitive rules and as for quatization, the accuracy depreciates as it causes inaccurate representation of information especially in the case of post-training quantitization.\n",
        "2.   Low rank approximations are easier to implement as they are not hardware reliant compared to quantization as it requires understanding hardware and bit wise computations making it hardware reliant.\n",
        "\n",
        "\n",
        "Demerits low rank approximations\n",
        "\n",
        "\n",
        "1.   Low computation efficiency, this is especially true for 5D datasets as the process can consume time than expected.  \n",
        "2.   Rank inconsistency where large ranks can reduce noise and lower ranks can lead to the loss of useful signals\n",
        "\n",
        "Alternative compression methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O81HH6D3Lugd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoWy4-iQIYJ0"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBFa6wXqAKgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4f15f0-2121-4339-fb0b-4269d37f1db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.0.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.23)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.5)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-haiku optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzdlf_milUbR"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator, Mapping, Tuple\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from absl import app\n",
        "import haiku as hk\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "import math\n",
        "from numpy.linalg import svd\n",
        "\n",
        "Batch = Tuple[np.ndarray, np.ndarray]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsYJmUqz-uFT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTGxEfqnSmd"
      },
      "source": [
        "## Coding Challenge Part I : Debugging Challenge (10 Points)\n",
        "\n",
        "\n",
        "We are now going to explore using SVD to compute low rank approximations of the parameters of a small deep neural network. You are using a very simple toy model as a first baseline. Section 3 will give you the chance to improve baseline accuracy beyond this very simple model -- this is just a toy setting to first explore low rank approximations.\n",
        "\n",
        "The first part of this challenge is primarily a debugging challenge. It will require removing bugs in order to train a very simple network. We have introduced several bugs -- some are subtle and will not break your code but will degrade final performance. These subtle bugs are introduced to understand your grasp of fundamental machine learning principles. There are also more obvious bugs designed to break your code.\n",
        "\n",
        "* [**4 points**] Your goal is to get the code working. There are 4 bugs in the code, these are subtle bugs which are designed to impair test accuracy but not break the code. You will get partial points for each of the 4 bugs you find. After finding all bugs, your test performance should be around 67% test accuracy.\n",
        "\n",
        "* [**2 points**] We will give extra points for also adding improved documentation to each of the functions we introduce in this section, and for describing the fixes to the bugs.\n",
        "\n",
        "* [**4 points**] There are also two functions you will need to code up in this section -- we indicate where these code changes need to happen with TODO comments.\n",
        "\n",
        "* Do not alter the model architecture or the learning rate.\n",
        "\n",
        "\n",
        "Useful tips:\n",
        "* To iterate faster and avoid training for 10000 steps each time you want to test whether you have found all the bugs, a good sign you have caught the bugs is wheter after 1000/10000 steps your accuracy >40%.\n",
        "* The colab difftool is useful to track what code you have changed during the debugging challenge (incase you need to revert code). You can access this via tools > diff notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqpgWQJs-evw"
      },
      "outputs": [],
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "def net_fn(batch: Batch) -> jnp.ndarray:\n",
        "\n",
        "  x = normalize(batch[0]) # could normalization be done just once to save time?\n",
        "\n",
        "  # Do NOT alter the architecture definition below.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)\n",
        "\n",
        "def load_dataset(\n",
        "    split: str,\n",
        "    *,\n",
        "    is_training: bool,\n",
        "    batch_size: int,\n",
        ") -> Iterator[tuple]:\n",
        "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
        "  ds = tfds.load('cifar10', split=split, as_supervised=True).cache().repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def compute_loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
        "  x, y = batch\n",
        "  logits = net.apply(params, batch)\n",
        "  labels = jax.nn.one_hot(y, 10)\n",
        "\n",
        "  # TODO: add code below to compute the l2_loss variable\n",
        "  l2_loss = optax.l2_loss(logits,labels).sum()\n",
        "  weighted_l2_loss = 0.5 * l2_loss\n",
        "  softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "  return softmax_xent + (1e-4 * weighted_l2_loss) # Calculation should be positive not negative\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def compute_accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  '''compute the accuracy using number of correctly predicted over total predicted  '''\n",
        "  predictions = net.apply(params, batch)\n",
        "  x, y = batch\n",
        "  # TODO: add code below to compute the accuracy over the batch.\n",
        "  labels = jax.nn.one_hot(y, 10)\n",
        "  target_class = jnp.argmax(labels, axis=1)\n",
        "  predicted_class = jnp.argmax(predictions, axis=1) # could this variable name be logits for consistency ?\n",
        "  accuracy = jnp.mean(predicted_class == target_class)\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update(\n",
        "    params: hk.Params,\n",
        "    opt_state: optax.OptState,\n",
        "    batch: Batch,\n",
        ") -> Tuple[hk.Params, optax.OptState]:\n",
        "  '''Update the gradient and get the current state at each epoch '''\n",
        "  grads = jax.grad(compute_loss)(params, batch)\n",
        "  updates, opt_state = opt.update(grads, opt_state)\n",
        "  new_params = optax.apply_updates(params, updates)\n",
        "  return new_params, opt_state\n",
        "\n",
        "@jax.jit\n",
        "def ema_update(params, avg_params):\n",
        "  return optax.incremental_update(params, avg_params, step_size=0.001)\n",
        "\n",
        "\n",
        "def normalize(images):\n",
        "  mean = np.asarray(CIFAR10_MEAN)\n",
        "  std = np.asarray(CIFAR10_STD)\n",
        "  x = images.astype(jnp.int8) / 255.\n",
        "  x /- mean\n",
        "  x /= std\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5iI930cIjzM"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4-HuMSH_Cbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6e3d1d29-f0e9-49b4-9a7b-3e07be2e883f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 0] Validation / Test accuracy: 0.099 / 0.100.\n",
            "[Step 1000] Validation / Test accuracy: 0.348 / 0.349.\n",
            "[Step 2000] Validation / Test accuracy: 0.466 / 0.465.\n",
            "[Step 3000] Validation / Test accuracy: 0.474 / 0.486.\n",
            "[Step 4000] Validation / Test accuracy: 0.480 / 0.482.\n",
            "[Step 5000] Validation / Test accuracy: 0.480 / 0.482.\n",
            "[Step 6000] Validation / Test accuracy: 0.480 / 0.482.\n",
            "[Step 7000] Validation / Test accuracy: 0.479 / 0.481.\n",
            "[Step 8000] Validation / Test accuracy: 0.479 / 0.480.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-80df0835bd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m           f\"{val_accuracy:.3f} / {test_accuracy:.3f}.\")\n\u001b[1;32m     22\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mavg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "\n",
        "# Do not change learning rate\n",
        "opt = optax.adam(1e-3)\n",
        "\n",
        "train = load_dataset(\"train[:90%]\", is_training=True, batch_size=1000) #The training dataset should be 80% of the whole datataset\n",
        "validation = load_dataset(\"train[90%:]\", is_training=False, batch_size=10000)  #The validation dataset should be 10% of the whole datataset\n",
        "test = load_dataset(\"test\", is_training=False, batch_size=10000)\n",
        "\n",
        "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "# Do not alter the number of steps\n",
        "for step in range(10001):\n",
        "  if step % 1000 == 0:\n",
        "    val_accuracy = compute_accuracy(avg_params, next(validation))\n",
        "    test_accuracy = compute_accuracy(avg_params, next(test))\n",
        "    val_accuracy, test_accuracy = jax.device_get(\n",
        "        (val_accuracy, test_accuracy))\n",
        "    print(f\"[Step {step}] Validation / Test accuracy: \"\n",
        "          f\"{val_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "  params, opt_state = update(params, opt_state, next(train))\n",
        "  avg_params = ema_update(params, avg_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWQhbV-MPQA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQmOspeD0jCh"
      },
      "source": [
        "## Coding Challenge Part 2: Compression through Low Rank Approximation (8 points)\n",
        "\n",
        "In this section, you will add code to compute the low rank approximation and to compute evaluation metrics. We will evaluate whether the low rank approximation allows for speed up in inference time. We define inference time as the average time to compute the prediction for all examples in the test set.\n",
        "\n",
        "* [**4 points**] You will need to add code to define both the compute_eval_metrics and rank_approximated weight function.\n",
        "* [**4 points**] Q4 and Q5 are worth 2 points each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdZqO7W_KSX8"
      },
      "outputs": [],
      "source": [
        "import time as t\n",
        "def compute_eval_metrics(params, batch, n_samples):\n",
        "  ''' This computes the time it takes to make inference for the uncompressed network'''\n",
        "  duration_list = []\n",
        "  accuracy_list = []\n",
        "  for _ in range(n_samples):\n",
        "    start = t.time()\n",
        "    acc = compute_accuracy(params, batch)\n",
        "    duration = t.time() - start\n",
        "    duration_list.append(duration)\n",
        "    accuracy_list.append(acc)\n",
        "  return accuracy_list, duration_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8U8Nlp9IS4q"
      },
      "outputs": [],
      "source": [
        "def rank_approximated_weight(weight: jnp.ndarray, rank_fraction: float):\n",
        "  ''' This computes the SVD of the networks's weight and returns the rank approximations of the weight'''\n",
        "  size = weight.shape[1]\n",
        "  rank  = int(rank_fraction * size )\n",
        "  u,s,v = svd(weight,full_matrices =False)\n",
        "  u = u[:,:rank]\n",
        "  v = v[:rank,:]\n",
        "  return u, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvm9InR4JG4F"
      },
      "source": [
        "### Evaluations at different ranks\n",
        "\n",
        "The code below first replaces the weights with the low rank factorizations at different rank fractions. For each modified net, we compute the new eval accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEjLxaDPEGEY",
        "outputId": "ace10b70-61cb-401f-e7bb-8a26f7a65639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at 1.0\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.101.\n",
            "Rank Fraction / Duration: 1.00 / 0.1850.\n",
            "Evaluating the model at 0.9\n",
            "Rank Fraction / Test accuracy: 0.90 / 0.101.\n",
            "Rank Fraction / Duration: 0.90 / 0.1859.\n",
            "Evaluating the model at 0.8\n",
            "Rank Fraction / Test accuracy: 0.80 / 0.118.\n",
            "Rank Fraction / Duration: 0.80 / 0.1844.\n",
            "Evaluating the model at 0.7000000000000001\n",
            "Rank Fraction / Test accuracy: 0.70 / 0.101.\n",
            "Rank Fraction / Duration: 0.70 / 0.1865.\n",
            "Evaluating the model at 0.6000000000000001\n",
            "Rank Fraction / Test accuracy: 0.60 / 0.100.\n",
            "Rank Fraction / Duration: 0.60 / 0.1836.\n",
            "Evaluating the model at 0.5000000000000001\n",
            "Rank Fraction / Test accuracy: 0.50 / 0.100.\n",
            "Rank Fraction / Duration: 0.50 / 0.1864.\n",
            "Evaluating the model at 0.40000000000000013\n",
            "Rank Fraction / Test accuracy: 0.40 / 0.102.\n",
            "Rank Fraction / Duration: 0.40 / 0.1841.\n",
            "Evaluating the model at 0.30000000000000016\n",
            "Rank Fraction / Test accuracy: 0.30 / 0.100.\n",
            "Rank Fraction / Duration: 0.30 / 0.1848.\n",
            "Evaluating the model at 0.20000000000000018\n",
            "Rank Fraction / Test accuracy: 0.20 / 0.100.\n",
            "Rank Fraction / Duration: 0.20 / 0.1832.\n",
            "Evaluating the model at 0.1000000000000002\n",
            "Rank Fraction / Test accuracy: 0.10 / 0.099.\n",
            "Rank Fraction / Duration: 0.10 / 0.1846.\n"
          ]
        }
      ],
      "source": [
        "rank_truncated_params = deepcopy(params)\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "  # iterate through fractions of 100% to 10%\n",
        "  print(f\"Evaluating the model at {rank_fraction}\")\n",
        "  for layer in params.keys():\n",
        "    if 'conv' in layer:\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    # TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    rank_truncated_params[layer]['w'] = u@v\n",
        "\n",
        "  test_batch = next(test)\n",
        "  # we compute metrics over 50 samples to reduce noise in the measurement.\n",
        "  n_samples = 50\n",
        "  # TODO: complete coding the compute_eval_metrics function to compute latency 50 seperate times given the batch passed to compute_eval_metrics. Return the average across all latencies you store.\n",
        "  test_accuracy, latency = compute_eval_metrics(rank_truncated_params, next(test), n_samples)\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(latency):.4f}.\")\n",
        "  ranks_and_times.append((rank_fraction, np.mean(latency)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzyvqIr38eWw"
      },
      "source": [
        "### Q4: What do you observe as the relationship between rank fraction and test accuracy?\n",
        "\n",
        "Plot this relationship showing accuracy (y-axis) vs rank percentage of the matrix (x-axis). You should use the ranks_and_accuracies list computed above.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "TCdYJ6lSEKM9",
        "outputId": "ad652318-34ef-4cb2-a3ae-a53e35a30d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ef859a30850>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbOElEQVR4nO3df5BcZZ3v8ffHSUKyCiaEkYUETdQsbpBf2snq1pWloCSBqyRi2BvKwmQXFm9ZrPcWBbXh7t1lCVqo2V1dvAhExMUtkV8LOHKBVDZCLbuLbjohBAJGRogwAXVMCMZr+BHyvX/0M3DS6Ux6Zp7T0818XlVd6fM85zn97TM9+cw555kzigjMzMxyeMtoF2BmZm8eDhUzM8vGoWJmZtk4VMzMLBuHipmZZTNutAsYTYcddljMmDFjtMswM+so69at+1VEdDfqG9OhMmPGDKrV6miXYWbWUST9bH99Pv1lZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmls2Ynv1lb153PbyVFas289yOXRw5eRKXzDuahSdOG+2yzN70HCr2pnPXw1u59I5H2fXqawBs3bGLS+94FMDBYlayUk9/SZovabOkXknLGvSfJGm9pN2SFtX13Sdph6S769oflLQhPZ6TdFdqP1nSi4W+vy7zvVn7WrFq8+uBMmDXq6+xYtXmUarIbOwo7UhFUhdwNfBRoA9YK6knIh4vrPYMsBS4uMEmVgC/A3ym2BgRHym8xj8D3yt0PxgRH8vyBqxjPbdj15DazSyfMo9U5gK9EfFURLwC3AwsKK4QEVsiYiOwp35wRKwBdu5v45IOAU4B7spatXW8IydPGlK7meVTZqhMA54tLPeltlwWAmsi4teFtg9LekTSvZKOaTRI0gWSqpKq/f39GcuxdnHJvKOZNL5rr7ZJ47u4ZN7Ro1SR2djRyVOKzwG+W1heD7wrIo4HvsZ+jmAiYmVEVCKi0t3d8H5o1uEWnjiNK886lmmTJyFg2uRJXHnWsb5Ib9YCZc7+2gocVVientpGTNJh1E6vfWKgrXjEEhH3SPq6pMMi4lc5XtM6y8ITpzlEzEZBmUcqa4FZkmZKmgAsBnoybXsRcHdEvDTQIOl3JSk9n0vtvW3L9HpmZtaE0kIlInYDFwKrgCeAWyNik6Tlks4EkDRHUh9wNnCdpE0D4yU9CNwGnCqpT9K8wuYXs/epL6gFzWOSHgGuAhZHRJT1/szMbF8ay//vViqV8N9TMTMbGknrIqLSqK+TL9SbmVmbcaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2pYaKpPmSNkvqlbSsQf9JktZL2i1pUV3ffZJ2SLq7rv0fJT0taUN6nJDaJemq9FobJX2gzPdmZmb7Ki1UJHUBVwOnA7OBcyTNrlvtGWApcFODTawAzt3P5i+JiBPSY0NqOx2YlR4XANeM7B2YmdlQlXmkMhfojYinIuIV4GZgQXGFiNgSERuBPfWDI2INsHMIr7cA+HbU/BCYLOmI4ZdvZmZDVWaoTAOeLSz3pbYcvpBOcX1F0kFDeT1JF0iqSqr29/dnKsfMzKAzL9RfCrwPmAMcCvzFUAZHxMqIqEREpbu7u4z6zMzGrDJDZStwVGF5emobkYh4Pp3iehn4FrXTbKW9npmZNa/MUFkLzJI0U9IEYDHQM9KNDlwnkSRgIfBY6uoBPp1mgX0IeDEinh/p65mZWfPGlbXhiNgt6UJgFdAF3BARmyQtB6oR0SNpDnAnMAX4uKTLI+IYAEkPUjvN9TZJfcB5EbEK+I6kbkDABuC/p5e8BzgD6AV+C/xJWe/NzMwaU0SMdg2jplKpRLVaHe0yzMw6iqR1EVFp1NeJF+rNzKxNOVTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCybUkNF0nxJmyX1SlrWoP8kSesl7Za0qK7vPkk7JN1d1/6dtM3HJN0gaXxqP1nSi5I2pMdfl/nezMxsX6WFiqQu4GrgdGA2cI6k2XWrPQMsBW5qsIkVwLkN2r8DvA84FpgEnF/oezAiTkiP5SN7B2ZmNlRlHqnMBXoj4qmIeAW4GVhQXCEitkTERmBP/eCIWAPsbNB+TyTAfwLTS6nezMyGrMxQmQY8W1juS21ZpNNe5wL3FZo/LOkRSfdKOmY/4y6QVJVU7e/vz1WOmZnR2Rfqvw78a0Q8mJbXA++KiOOBrwF3NRoUESsjohIRle7u7haVamY2NpQZKluBowrL01PbiEm6DOgGLhpoi4hfR8Rv0vN7gPGSDsvxemZm1pwyQ2UtMEvSTEkTgMVAz0g3Kul8YB5wTkTsKbT/riSl53OpvbdtI309MzNrXmmhEhG7gQuBVcATwK0RsUnScklnAkiaI6kPOBu4TtKmgfGSHgRuA06V1CdpXuq6FjgceKhu6vAi4DFJjwBXAYvTxXwzM2sRjeX/dyuVSlSr1dEuw8yso0haFxGVRn2dfKHezMzajEPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyyKTVUJM2XtFlSr6RlDfpPkrRe0m5Ji+r67pO0Q9Ldde0zJf0obfMWSRNS+0FpuTf1zyjzvZmZ2b5KCxVJXcDVwOnAbOAcSbPrVnsGWArc1GATK4BzG7R/CfhKRLwXeAE4L7WfB7yQ2r+S1jMzsxYq80hlLtAbEU9FxCvAzcCC4goRsSUiNgJ76gdHxBpgZ7FNkoBTgNtT043AwvR8QVom9Z+a1jczsxYpM1SmAc8WlvtS20hMBXZExO4G23z99VL/i2n9vUi6QFJVUrW/v3+E5ZiZWdGYu1AfESsjohIRle7u7tEux8zsTaXMUNkKHFVYnp7aRmIbMFnSuAbbfP31Uv/b0/pmZtYiZYbKWmBWmq01AVgM9IxkgxERwP3AwEyxJcD30vOetEzq/0Fa38zMWqS0UEnXNS4EVgFPALdGxCZJyyWdCSBpjqQ+4GzgOkmbBsZLehC4jdoF9z5J81LXXwAXSeqlds3km6n9m8DU1H4RsM8UZjMzK5fG8g/zlUolqtXqaJdhZtZRJK2LiEqjvjF3od7MzMrTVKhIOqhB26H5yzEzs07W7JHKHZLGDyxIOgJYXU5JZmbWqZoNlbuAWyV1pXtqrQIuLasoMzPrTOMOvApExDfStOC7gBnAZyLiP8oszMzMOs+goSLpouIi8E5gA/AhSR+KiL8vszgzM+ssBzpSObhu+Y79tJuZmQ0eKhFxeasKMTOzztfUNRVJvwdcTO16yutjIuKUcsoyM7NO1FSoULtdyrXA9cBr5ZVjZmadrNlQ2R0R15RaiZmZdbxmf0/l+5I+K+kISYcOPEqtzMzMOk6zRyoDt5S/pNAWwLvzlmNmZp2s2V9+nFl2IWZm1vmaPVJB0vuB2cDEgbaI+HYZRZmZWWdqdkrxZcDJ1ELlHuB04N8Ah4qZmb2u2Qv1i4BTgZ9HxJ8Ax1P7G/BmZmavazZUXoqIPcBuSYcAvwSOKq8sMzPrRAcMFUkCNkqaDHwDWAesBx5qYux8SZsl9Ura52/GSzpJ0npJuyUtqutbIunJ9FiS2g6WtKHw+JWkr6a+pZL6C33nN7UHzMwsmwNeU4mIkDQ3InYA10q6DzgkIjYONk5SF3A18FGgD1grqSciHi+s9gywlNotYIpjDwUuAyrUpi6vS2NfAE4orLeON25yCXBLRFx4oPdkZmblaPb013pJcwAiYsuBAiWZC/RGxFMR8QpwM7CguEJhW3vqxs4DVkfE9hQkq4H5xRXS/cjeATzY5HswM7OSNRsqfwA8JOmnkjZKelTSgYJlGvBsYbkvtTWjmbGLqR2ZRKHtk6m+2yU1vOYj6QJJVUnV/v7+JssxM7NmNPt7KvNKrWJ4FgPnFpa/D3w3Il6W9BngRmCfuyhHxEpgJUClUon6fjMzG75mf6P+Z8PY9lb2niE2PbU1O/bkurEPDCxIOh4YFxHrCjVuK6x/PfDloZVrZmYj1ezpr+FYC8ySNDP9ffvFQE+TY1cBp0maImkKcFpqG3AO8N3iAElHFBbPBJ4YduVmZjYsTd+mZagiYrekC6mFQRdwQ0RskrQcqEZET7r4fycwBfi4pMsj4piI2C7pCmrBBLA8IrYXNv/HwBl1L/k5SWcCu4Ht1GaVmZlZC2nv69xjS6VSiWq1OtplmJl1FEnrIqLSqK/M019mZjbGOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCybUkNF0nxJmyX1SlrWoP8kSesl7Za0qK5viaQn02NJof2BtM0N6fGO1H6QpFvSa/1I0owy35uZme1rXFkbltQFXA18FOgD1krqiYjHC6s9AywFLq4beyhwGVABAliXxr6QVvlURNT/cfnzgBci4r2SFgNfAv5b5rdlZmaDKPNIZS7QGxFPRcQrwM3AguIKEbElIjYCe+rGzgNWR8T2FCSrgfkHeL0FwI3p+e3AqZI00jdhZmbNKzNUpgHPFpb7UluOsd9Kp77+qhAcr4+JiN3Ai8DU+g1LukBSVVK1v7+/yXLMzKwZnXih/lMRcSzwkfQ4dyiDI2JlRFQiotLd3V1KgWZmY1WZobIVOKqwPD21jWhsRAz8uxO4idpptr3GSBoHvB3YNszazcxsGMoMlbXALEkzJU0AFgM9TY5dBZwmaYqkKcBpwCpJ4yQdBiBpPPAx4LE0pgcYmCW2CPhBRESm92JmZk0obfZXROyWdCG1gOgCboiITZKWA9WI6JE0B7gTmAJ8XNLlEXFMRGyXdAW1YAJYntreSi1cxqdt/gvwjbTON4F/ktQLbKcWYmZm1kIayz/MVyqVqFbrZyabmdlgJK2LiEqjvk68UG9mZm3KoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtmUGiqS5kvaLKlX0rIG/SdJWi9pt6RFdX1LJD2ZHktS2+9I+r+Sfixpk6QvFtZfKqlf0ob0OL/M92ZmZvsaV9aGJXUBVwMfBfqAtZJ6IuLxwmrPAEuBi+vGHgpcBlSAANZJ6gFeBv42Iu6XNAFYI+n0iLg3Db0lIi4s6z2ZmdngyjxSmQv0RsRTEfEKcDOwoLhCRGyJiI3Anrqx84DVEbE9Il4AVgPzI+K3EXF/GvsKsB6YXuJ7MDOzISgzVKYBzxaW+1JblrGSJgMfB9YUmj8paaOk2yUd1WjDki6QVJVU7e/vb7IcMzNrRkdeqJc0DvgucFVEPJWavw/MiIjjqB3Z3NhobESsjIhKRFS6u7tbU7CZ2RhRZqhsBYpHC9NTW46xK4EnI+KrAw0RsS0iXk6L1wMfHHLFZmY2ImWGylpglqSZ6aL6YqCnybGrgNMkTZE0BTgttSHp88Dbgf9ZHCDpiMLimcATI6zfzMyGqLRQiYjdwIXUwuAJ4NaI2CRpuaQzASTNkdQHnA1cJ2lTGrsduIJaMK0FlkfEdknTgb8EZgPr66YOfy5NM34E+By1WWVmZtZCiojRrmHUVCqVqFaro13GmHLXw1tZsWozz+3YxZGTJ3HJvKNZeGKz8zfMrB1IWhcRlUZ9pf2eilm9ux7eyqV3PMquV18DYOuOXVx6x6MADhazN4mOnP1lnWnFqs2vB8qAXa++xopVm0epIjPLzaFiLfPcjl1DajezzuNQsZY5cvKkIbWbWefxNRVrmUvmHb3XNRWASeO7uGTe0aNYVefypIdyeL+OjEPFWmbgG9PfsCPnSQ/l8H4dOYeKtdTCE6f5mzODwSY9eP8On/fryPmailkH8qSHcni/jpxDxawDedJDObxfR86hYtaBLpl3NJPGd+3V5kkPI+f9OnK+pmLWgTzpoRzeryPne3/53l9mNobkmDLte3+ZmVlLpkz7moqZ2RjRivvvOVTMzMaIVkyZdqiYmY0RrZgy7VAxMxsjWjFl2hfqzczGiFZMmS41VCTNB/4B6AKuj4gv1vWfBHwVOA5YHBG3F/qWAP87LX4+Im5M7R8E/hGYBNwD/I+ICEmHArcAM4AtwB9HxAu531M73MG0HWqwvPw1tZEYyuen7PvvlXb6S1IXcDVwOjAbOEfS7LrVngGWAjfVjT0UuAz4A2AucJmkKan7GuDPgFnpMT+1LwPWRMQsYE1azmpgOt7WHbsI3piOd9fDW3O/VFvXYHn5a2oj0W6fnzKvqcwFeiPiqYh4BbgZWFBcISK2RMRGYE/d2HnA6ojYno42VgPzJR0BHBIRP4zab21+G1iYxiwAbkzPbyy0Z9MOfw63HWqwvPw1tZFot89PmaEyDXi2sNyX2kYydlp63mibh0fE8+n5z4HDG21Y0gWSqpKq/f39TZZT0w53MG2HGiwvf01tJNrt8/OmnP2VjmIa3n8mIlZGRCUiKt3d3UPabjvcwbQdarC8/DW1kWi3z0+ZobIVOKqwPD21jWTs1vS80TZ/kU6Pkf795TBqHlQ73MG0HWqwvPw1tZFot89PmaGyFpglaaakCcBioKfJsauA0yRNSRfoTwNWpdNbv5b0IUkCPg18L43pAZak50sK7dksPHEaV551LNMmT0LAtMmTuPKsY1s6S6cdarC8/DW1kWi3z0+pdymWdAa1KcNdwA0R8QVJy4FqRPRImgPcCUwBXgJ+HhHHpLF/CvyvtKkvRMS3UnuFN6YU3wv8eZpSPBW4FXgn8DNqU4q3D1af71JszfB0X3sze/XVV+nr6+Oll17ap2/ixIlMnz6d8ePH79U+2F2Kfet7h4oNov6urlA7teAjCXuzePrppzn44IOZOnUqtRNANRHBtm3b2LlzJzNnztxrzGCh8qa8UG+WS7tN1zTL7aWXXtonUAAkMXXq1IZHMINxqJgNot2ma5qVoT5QDtQ+GIeK2SDabbqmWbtzqJgNot2ma5q1O9+l2GwQrbirq9loi4iGp7qGM5HLoWJ2AGXf1dVsNE2cOJFt27btd/bXxIkTh7Q9h4qZ2Rg2ffp0+vr6aHQvxIHfUxkKh4qZ2Rg2fvz4fX4PZSR8od7MzLJxqJiZWTYOFTMzy2ZM3/tLUj+1m092isOAX412EUPkmlunE+vuxJqhM+vOWfO7IqLhH6Qa06HSaSRV93cTt3blmlunE+vuxJqhM+tuVc0+/WVmZtk4VMzMLBuHSmdZOdoFDINrbp1OrLsTa4bOrLslNfuaipmZZeMjFTMzy8ahYmZm2ThUWkjSfEmbJfVKWtag/yRJ6yXtlrSoru/LkjZJekLSVUq3E5V0n6RHUt+1krpS+99I2ippQ3qc0S41F/p7JD1WWD5U0mpJT6Z/pwyn5lGou233taQH0jYHantHaj9I0i3ptX4kaUYH1LxUUn+h/fzh1Fxi3RMkrZT0E0k/lvTJ1N7O+3p/NQ9/X0eEHy14AF3AT4F3AxOAR4DZdevMAI4Dvg0sKrT/IfDvaRtdwEPAyanvkPSvgH8GFqflvwEubseaU/9ZwE3AY4W2LwPL0vNlwJc6pO623dfAA0Clwet9Frg2PV8M3NIBNS8F/k8bfy9eDnw+PX8LcFgH7Ov91Tzsfe0jldaZC/RGxFMR8QpwM7CguEJEbImIjcCeurEBTKT2YToIGA/8Io35dVpnXOrPOfOilJolvQ24CPh83ZgFwI3p+Y3Awg6pO4dSah5EcV/fDpxaf0TWhjXnUlbdfwpcmcbviYiB315v5329v5qHzaHSOtOAZwvLfantgCLiIeB+4Pn0WBURTwz0S1oF/BLYSe1DO+BCSRsl3TDMU0ll1XwF8HfAb+uGHR4Rz6fnPwcOH0bNo1E3tO++BvhWOoXxV4X/zF5/vYjYDbwITG3zmgE+mfbz7ZKOGmK9pdUtaXJa5Yp0Cuo2SQOf37bc1weoGYa5rx0qHUDSe4HfB6ZT+yCdIukjA/0RMQ84gtpPIaek5muA9wAnUPsg/V071CzpBOA9EXHnYOOjdgze8vnuw6y7Lfd16v5URBwLfCQ9zm1lbfszzJq/D8yIiOOA1bzx03/LDFL3uNT2HxHxAWqnmP621fU1Msyah72vHSqtsxUopv301NaMTwA/jIjfRMRvgHuBDxdXiIiXgO+RDokj4hcR8VpE7AG+Qe3wuR1q/jBQkbQF+Dfg9yQ9kMb8QtIRAOnfXw6j5pbX3cb7mojYmv7dSe1a0EBtr7+epHHA24Ft7VxzRGyLiJfT+OuBDw6x3jLr3kbtCPaOtN5twAfqX6/N9vV+ax7JvnaotM5aYJakmZImULtg19Pk2GeAP5I0TtJ44I+AJyS9rfCf8DjgvwI/TstHFMZ/AniMoctec0RcExFHRsQM4L8AP4mIk9OYHmBJer6EWkgOR0vrbtd9nZYPSzWOBz5WqK24rxcBP0hHh21bc91+PhN4guEp4/MR1H66PzmtdyrweHrelvt6sJpHtK+Hc3Xfj2HPOjkD+Am1WRx/mdqWA2em53OonSv9f9R+itgUb8z8uC59YR8H/j61H54+bBupfeN9DRiX+v4JeDT19QBHtEPNdduewd6zqKYCa4AngX8BDm2XfX2AuttyXwNvBdalujYB/wB0pb6J1H4y7QX+E3h3B9R8ZWp7hNo1gve10+cDeBfwr6n2NcA723lfH6DmYe9r36bFzMyy8ekvMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmYtJGmypM+m50dKuv1AY8w6iacUm7WQarc9vzsi3j/KpZiVYtxoF2A2xnwReI+kDdR+yfP3I+L9kpZSuyvzW4FZ1O7BNIHafa9eBs6IiO2S3gNcDXRTu8XGn0XEj1v/Nswa8+kvs9ZaBvw0Ik4ALqnrez+1v9cyB/gC8NuIOJHajf4+ndZZCfx5RHwQuBj4ekuqNmuSj1TM2sf9UbuJ4k5JL1K7LxPUbgFzXPp7Ln8I3Fa4G/xBrS/TbP8cKmbt4+XC8z2F5T3UvlffAuxIRzlmbcmnv8xaaydw8HAGRu2vfD4t6WwA1RyfszizkXKomLVQRGwD/l3SY8CKYWziU8B5kh6hdhfZBQdY36ylPKXYzMyy8ZGKmZll41AxM7NsHCpmZpaNQ8XMzLJxqJiZWTYOFTMzy8ahYmZm2fx/2YMSoCV/zAMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## TODO: add your code below to plot the relationship between time and test set accuracy\n",
        "accuracies =list(zip(*ranks_and_accuracies))[1]\n",
        "time = list(zip(*ranks_and_times))[1]\n",
        "plt.scatter(time,accuracies)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('rank')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRkI8rAO5UYe"
      },
      "source": [
        "### Q5: Does replacing the weight matrix with the low factor matrix result in latency speed ups?\n",
        "\n",
        "Plot the relationship of time (y-axis) vs rank percentage (x-axis). To do so add code to compute the ranks_and_times list.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "f7jlMYxhi7E-",
        "outputId": "c8a9f443-ee5e-4465-d90d-7a95ef0116b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ef859a3f810>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## TODO: add your code below to plot the relationship between time and rank percentage\n",
        "percentage  =list(zip(*ranks_and_accuracies))[0]\n",
        "time = list(zip(*ranks_and_times))[1]\n",
        "plt.scatter(time,percentage)\n",
        "# plt.plot(percentage, label='percentage')\n",
        "# plt.plot(time, label = 'time')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('rank')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR3JTDWb2QII"
      },
      "source": [
        "## Coding Challenge Part 3: Perform evaluations on the dataset in factorized space. (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OctdUxerSZut"
      },
      "outputs": [],
      "source": [
        "def low_rank_net_fn(batch: Batch, rank: float) -> jnp.ndarray:\n",
        "  x, y = batch\n",
        "  x = batch[0].astype(jnp.float32) / 255.\n",
        "  total_input_dim = np.prod(x.shape[1:])\n",
        "\n",
        "  # Do not alter the architecture code.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(int(rank * min(total_input_dim, 3000)), with_bias=False),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False),\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False),\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 1000), with_bias=False),\n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 10), with_bias=False),\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi2TN_WV-jgZ",
        "outputId": "d1bb5077-abc2-4051-e19d-e7df5a8e8780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at 1.00\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.099.\n",
            "Rank Fraction / Duration: 1.00 / 0.1821.\n",
            "Evaluating the model at 0.90\n",
            "Rank Fraction / Test accuracy: 0.90 / 0.099.\n",
            "Rank Fraction / Duration: 0.90 / 0.1848.\n",
            "Evaluating the model at 0.80\n",
            "Rank Fraction / Test accuracy: 0.80 / 0.099.\n",
            "Rank Fraction / Duration: 0.80 / 0.1831.\n",
            "Evaluating the model at 0.70\n",
            "Rank Fraction / Test accuracy: 0.70 / 0.099.\n",
            "Rank Fraction / Duration: 0.70 / 0.1845.\n",
            "Evaluating the model at 0.60\n",
            "Rank Fraction / Test accuracy: 0.60 / 0.099.\n",
            "Rank Fraction / Duration: 0.60 / 0.1826.\n",
            "Evaluating the model at 0.50\n",
            "Rank Fraction / Test accuracy: 0.50 / 0.099.\n",
            "Rank Fraction / Duration: 0.50 / 0.1844.\n",
            "Evaluating the model at 0.40\n",
            "Rank Fraction / Test accuracy: 0.40 / 0.099.\n",
            "Rank Fraction / Duration: 0.40 / 0.1830.\n",
            "Evaluating the model at 0.30\n",
            "Rank Fraction / Test accuracy: 0.30 / 0.099.\n",
            "Rank Fraction / Duration: 0.30 / 0.1843.\n",
            "Evaluating the model at 0.20\n",
            "Rank Fraction / Test accuracy: 0.20 / 0.099.\n",
            "Rank Fraction / Duration: 0.20 / 0.1822.\n",
            "Evaluating the model at 0.10\n",
            "Rank Fraction / Test accuracy: 0.10 / 0.099.\n",
            "Rank Fraction / Duration: 0.10 / 0.1849.\n"
          ]
        }
      ],
      "source": [
        "vanilla_to_low_rank_map = {\n",
        "    'conv2_d': 'conv2_d',\n",
        "    'conv2_d_1': 'conv2_d_1',\n",
        "    'linear': ['linear', 'linear_1'],\n",
        "    'linear_1': ['linear_2', 'linear_3'],\n",
        "    'linear_2': ['linear_4', 'linear_5'],\n",
        "    'linear_3': ['linear_6', 'linear_7'],\n",
        "    'linear_4': ['linear_8', 'linear_9']\n",
        "}\n",
        "\n",
        "\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "  low_rank_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "  low_rank_net_fn_partial = partial(low_rank_net_fn, rank=rank_fraction)\n",
        "\n",
        "  net = hk.without_apply_rng(hk.transform(low_rank_net_fn_partial))\n",
        "  low_rank_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "\n",
        "  print(f\"Evaluating the model at {rank_fraction:.2f}\")\n",
        "\n",
        "  for layer in vanilla_to_low_rank_map.keys():\n",
        "    if 'conv' in layer:\n",
        "      low_rank_params[layer] = params[layer]\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    # TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][0]]['w'] = u\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['w'] = v\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['b'] = params[layer]['b']\n",
        "\n",
        "  # TODO: modify the compute_eval_metrics function below to compute the time taken for inference.\n",
        "  test_accuracy, duration = compute_eval_metrics(rank_truncated_params, next(test), 50)\n",
        "  ranks_and_times.append((rank_fraction, np.mean(duration)))\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(duration):.4f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObBn-Pf_996r"
      },
      "source": [
        "### Q6: Plot a curve showing time vs rank percentage of the matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0bJJFL4LM7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7af3441b-2428-4cfa-9641-febdf153eb36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ef8598c3650>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO: add code to plot the relationship between time vs percentage rank of the matrix.\n",
        "percentage  =list(zip(*ranks_and_accuracies))[0]\n",
        "time = list(zip(*ranks_and_times))[1]\n",
        "plt.scatter(time,percentage)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('percentage')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "313ALwDu93k1"
      },
      "source": [
        "### Q7: What do you observe between time and the percentage rank of the matrix.\n",
        "\n",
        "### Put your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcBKkogM6uV"
      },
      "source": [
        "The highest rank takes the shortest time, and the lowest rank takes the ,most time.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEAu9Vu-0rWX"
      },
      "source": [
        "## Coding Challenge Part 3: Take this Further (10 bonus points)\n",
        "\n",
        "This part of the challenge is designed to be open ended. If you wanted to show some more skills, here is your chance to shine. We include two options below -- **only do one of the options**:\n",
        "\n",
        "**Challenge 1:** Implement a change that isn't SVD but minimizes inference latency while preserving accuracy. Can you outperform SVD?\n",
        "\n",
        "**Challenge 2:** Improve the quality of code for this takehome. Pretend you are reviewing a peer and add comments to cells with suggestions of how to improve the code quality. Try and make your comments action orientated and precise.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-v-iHTH3nasL",
        "UHGqpn3tkFRL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}